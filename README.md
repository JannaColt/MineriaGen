# MINER칈A GEN칍MICA 
## CALIDAD, ENSAMBLE Y ANOTACI칍N

Contiene pipeline para ensamble y miner칤a gen칩mica de shotgun sequence con google colab

El protocolo de manera general:

![Diagrama de flujo_An치lisis](https://user-images.githubusercontent.com/13104654/211899391-66c4a856-e193-44f2-baae-0ad84895b78a.png)

![PipelineA](https://user-images.githubusercontent.com/13104654/211914431-9c9197e0-58b6-4e54-a068-221093935a43.png)

![PipelineB](https://user-images.githubusercontent.com/13104654/211915131-852fbab8-fc34-4ba3-a3f7-d91135098e47.png)

Antes que nada tenemos que instalar las herramientas que usaremos en la nube.
Desde el cuaderno establecido primeramente se instalan todos los paquetes que se usar치n y al final se monta el drive en el que se estar치 trabajando. Es preferible que esto se haga desde el inicio ya que cuando se instala un nuevo paquete se reinicia el entorno y lo que anteriormente llamamos ya no estar치 disponible (cada vez que se quiera hacer el procedimiento ya que el cuaderno/entorno se ha cerrado hay que instalar todo de nuevo y hacer el montaje del drive). 

## 1. Instalaci칩n de Herramientas

Instalamos conda y lo llamamos para proceder con la instalaci칩n de los dem치s paquetes usando conda
```python
!pip install -q condacolab
import condacolab
condacolab.install()
```
Luego instalamos miniconda, para lo cual utilizamos un bloque que llame al shell: %%Shell, con lo cual estaremos utilizando los comandos que se usan cuando se utiliza el shell

```shell
%%shell
#Seguimos el pipeline de FranciscoZorrilla Metagem, el cual es para establecer relaciones metabolicas en metagenomas,
#sin embargo, los primeros pasos para el filtrado de calidad se pueden seguir tal cual

#instalar y ejecutar miniconda

sudo apt-get update
wget https://repo.continuum.io/Miniconda3-latest-Linux-x86_64.sh -O miniconda.sh;
bash miniconda.sh -b -p $HOME/miniconda
export PATH="$HOME/miniconda/bin:$PATH"
export PYTHONPATH="$PATH"
hash -r
conda config --set always_yes yes --set changeps1 no
conda update --q conda
```

Para realizar la instalaci칩n de FastQC utilizamos el siguiente bloque 
```python
# Instalar FastQC para identificar problemas de calidad en los datasets. 
!conda install -c bioconda fastqc -y

```
Adem치s podemos instalar fastp (puedes revisar la calidad ya sea utilizando fastqc o fastp, fastp tambi칠n sirve para preprocesar en lugar de trimmomatic y cutapad)

```python
# Instalar fastp para identificar problemas de calidad en los datasets. 
!conda install -c bioconda fastp -y
```


Ahora instalamos tambi칠n MultiQC, este agregar치 todos los an치lisis de calidad de los datos 
```python

# Instalar Multiqc que puede agregar y sumar todos los QC de los datos y alinear log data en un solo archivo 
!pip install multiqc
```
En caso de que querramos utilizar trimmomatic y no solo fastp podemos instalarlo a su vez.

```python
# Instalar Trimmomatic una herramienta flexible de trimming de lecturas para datos de Illumina NGS data 
! conda install -c bioconda trimmomatic -y
```

En caso de que queramos trabajar con transcriptomas (RNASeq) podemos utilizar Kallisto, usando las opciones:
Pseudobam

  --pseudobam outputs all pseudoalignments to a file pseudoalignments.bam in the output directory. This BAM file contains the pseudoalignments in BAM format,   ordered by reads so that each pseudoalignment of a read is adjacent in the BAM file.

  A detailed description of the SAM output is here.
 y GenomeBam

  --genomebam constructs the pseudoalignments to the transcriptome, but projects the transcript alignments to genome coordinates, resulting in split-read alignments. When the --genomebam option is supplied at GTF file must be given with the --gtf option. The GTF file, which can be plain text or gzipped, translates transcripts into genomic coordinates. We recommend downloading a the cdna FASTA files and GTF files from the same data source. The --chromosomes option can provide a length of the genomic chromosomes, this option is not neccessary, but gives a more consistent BAM header, some programs may require this for downstream analysis. kallisto does not require the genome sequence to do pseudoalignment, but downstream tools such as genome browsers will probably need it.
  
Es un programa para cuantificar la abundancia de &#x1F534; **Transcritos** a partir de datos de RNA-Seq en masa y unicelulares, o m치s generalmente de secuencias objetivo utilizando lecturas de secuenciaci칩n de alto rendimiento. Se basa en la novedosa idea de la pseudoalineaci칩n para determinar r치pidamente la compatibilidad de las lecturas con los objetivos, sin necesidad de alineaci칩n.


Una vista m치s detallada de kallisto la podemos encontrar aqu칤: [Manual Kallisto](http://pachterlab.github.io/kallisto/manual.html)

```python
# Puede que Kallisto no sea necesario: es para cuantificar abundancias de transcritos de datos de RNA-seq, o 
#o de forma mas general secuencias blanco usando high-throughput sequencing reads. Podemos omitirlo en este cuaderno 
! conda install -c bioconda kallisto -y
```

Para utilizar metagem tenemos que clonar el repositorio del autor. Metagem nos permite reconstruir modelos metab칩licos directamente de metagenomas. Se resumir치 un poco m치s adelante.
[Art칤culo de Metagem](https://academic.oup.com/nar/article/49/21/e126/6382386)


```shell
%%shell
#clonar el repositorio de metagem y despues moverse al directorio

git clone https://github.com/franciscozorrilla/metaGEM.git
cd metaGEM

#establecer mamba y metagem
/root/miniconda/bin/conda create --quiet --prefix ./envs/mamba mamba -c conda-forge && source /root/miniconda/bin/activate envs/mamba
mamba env create --quiet --prefix ./envs/metagem -f envs/metaGEM_env.yml

#activar metagem en el ambiente conda e instalar las herramientas pip
source /root/miniconda/bin/activate envs/metagem
pip install --quiet --user memote carveme smetana 

#desactivar metagem y activar el ambiente mamba
source /root/miniconda/bin/deactivate && source /root/miniconda/bin/activate envs/mamba

#Establecer metawrap y prokka-roary
mamba env create --quiet --prefix ./envs/metawrap -f envs/metaWRAP_env.yml
mamba env create --quiet --prefix ./envs/prokkaroary -f envs/prokkaroary_env.yml 
```

```python
#Para instalar megahit
!conda install -c bioconda megahit
```

## 2. Paqueter칤a Python

En caso de que necesitemos utilizar paquetes para graficar y para trabajar con archivos csv debemos importar los paquetes matplotlib y pandas

```python
import matplotlib.pyplot as plt
import pandas as pd #llamar pandas
```

## 3. Montar Drive en colab
Para montar el drive utilizamos el siguiente bloque, esto es necesario para poder utilizar los archivos que se guarden en el drive y para guardar outputs en el mismo:

```python
#Montar el drive para trabajar con los archivos dentro del drive
from google.colab import drive
drive.mount('/content/drive')

```
Ya establecida toda la paqueter칤a e instalados todos los pipelines podemos comenzar, teniendo en cuenta que nuestros archivos de secuencias (Pair-End o Single-End) deben estar guardados en nuestro drive.


## 4. Comencemos explorando las reads:

Las Lecturas com칰nmente se encuentran en formato FASTQ, muy similar al FASTA solo que contiene caracteres alfanum칠ricos que dan indicio de calidad asociada con cada nucle칩tido. Una imagen de la estructura de un archivo fastq la podemos observar m치s adelante en el apartado del pre-procesamiento.

[Estructura FASTQ](#5-pre-procesamiento-analisis-de-calidad-usando-fastqc-y-fastp)

Son Archivos (de texto o ficheros) muy grandes que no se pueden leer. Ciertos comandos te permiten observar aspectos clave (Head/tail/more - trabajando con ficheros en Linux). 

Para conocer un poco nuestras secuencias podemos utilizar script de bash. En este caso trabajamos con los siguientes archivos:


![Nuestro drive y la carpeta conteniendo las lecturas:](https://user-images.githubusercontent.com/13104654/204870524-c62fcf00-b097-4758-b0a8-406bee184927.png)

N칩tese que los archivos est치n comprimidos y se pueden seguir trabajando de esta manera.

### a) Explorando el contenido 

Utilizando el bash podemos observar encabezados y colas de archivos, con el comando zcat podemos trabajar con archivos comprimidos, en caso de no tenerlos comprimidos simplemente usamos cat. Como las lecturas son pair end, lo realizamos con ambos archivos.

```bash
#explorar el encabezado del archivo
%%bash
zcat /content/drive/MyDrive/Analisis_Posdoc/PR69/HA1AB3SS04_S4_L1_R1_001.fastq.gz | head
```
```shell
%%bash
zcat /content/drive/MyDrive/Analisis_Posdoc/PR69/HA1AB3SS04_S4_L1_R2_001.fastq.gz | head
```

```shell
#explorar el final para las lecturas R1 y R2
%%bash
zcat /content/drive/MyDrive/Analisis_Posdoc/PR69/HA1AB3SS04_S4_L1_R1_001.fastq.gz | tail -n 4
```
```shell

%%bash
zcat /content/drive/MyDrive/Analisis_Posdoc/PR69/HA1AB3SS04_S4_L1_R2_001.fastq.gz | tail -n 4
```

### b) Revision del numero y longitud de secuencias 

> (Tambi칠n revisamos que se encuentren pareados, esta parte se puede omitir ya que fastqc te muestra algunos de estos resultados)

El siguiente bloque permite revisar si los archivos est치n pareados
```bash
##Para explorar que los archivos est치n pareados
%%bash
zcat /content/drive/MyDrive/Analisis_Posdoc/PR69/HA1AB3SS04_S4_L1_R1_001.fastq.gz | wc -l
zcat /content/drive/MyDrive/Analisis_Posdoc/PR69/HA1AB3SS04_S4_L1_R2_001.fastq.gz | wc -l
```
si queremos saber cual es el n칰mero de secuencias usamos el siguiente (aunque es inespec칤fico), de nuevo usamos zgrep por que es un archivo comprimido.

```bash
##Explorar la cantidad de secuencias (deber칤a ser #####, n칰mero de l칤neas/4)
%%bash
zgrep '^@' /content/drive/MyDrive/Analisis_Posdoc/PR69/HA1AB3SS04_S4_L1_R1_001.fastq.gz | wc -l
zgrep '^@' /content/drive/MyDrive/Analisis_Posdoc/PR69/HA1AB3SS04_S4_L1_R2_001.fastq.gz | wc -l
```
para hacer que el anterior bloque haga una b칰squeda m치s espec칤fica tenemos

```bash
##Hay que ser m치s espec칤ficos para revisar la cantidad de secuencias
%%bash
zgrep '^@M02521' /content/drive/MyDrive/Analisis_Posdoc/PR69/HA1AB3SS04_S4_L1_R1_001.fastq.gz | wc -l
zgrep '^@M02521' /content/drive/MyDrive/Analisis_Posdoc/PR69/HA1AB3SS04_S4_L1_R2_001.fastq.gz | wc -l
```

Exploramos la longitud de secuencias. Para ello podemos usar awk, el cual es un comando (lenguaje de programaci칩n) que te permite trabajar operaciones matem치ticas con ficheros de texto (filtrando). M치s acerca de awk lo puedes encontrar [aqu칤](http://www.linuxfocus.org/English/September1999/article103.html#lfindex0) o [ac치](https://geekland.eu/uso-del-comando-awk-en-linux-y-unix-con-ejemplos/).

Para cada l칤nea de secuencia podemos contar cada caracter usando el par치metro NR (n칰mero de registros) y usando el contador.

```bash
%%bash
zcat /content/drive/MyDrive/Analisis_Posdoc/PR69/HA1AB3SS04_S4_L1_R1_001.fastq.gz | awk 'NR%4 == 2 {lengths[length($0)]++ ; counter++} END {for (l in lengths){print l, lengths[l]}; print "total reads: " counter}'

```
y podemos a침adir par치metros para imprimir en txt

```bash
%%bash
zcat /content/drive/MyDrive/Analisis_Posdoc/PR69/HA1AB3SS04_S4_L1_R1_001.fastq.gz | awk 'NR%4 == 2 {lengths[length($0)]++ ; counter++} END {for (l in lengths){print l, lengths[l]}}' | sort -n | uniq -c > /content/drive/MyDrive/Analisis_Posdoc/read_length1.txt
```

el txt generado lo podemos importar y transformar a csv para despu칠s graficarlo en matplotlib, para lo cual se pueden aplicar los siguientes bloques:

```python
read_file = pd.read_csv (r'/content/drive/MyDrive/Analisis_Posdoc/read_length1.txt',header=None)
read_file.to_csv (r'/content/drive/MyDrive/Analisis_Posdoc/read_lengthR1.csv', index=None,header=None)
```
Generar el df tipo decimal

```python
read_file[0] = read_file[0].astype(str)
df = read_file[0].apply(lambda x: x.strip(" "))
df = pd.DataFrame(df.str.split(' ',2).tolist(),
                                 columns = ['fips','length', 'ocurrences'])
df
df=df.astype(float)
```

y graficamos
```python
##Graficar la longitud de secuencia contra las ocurrencias
df.plot(x= 'ocurrences', y= 'length', kind ='line')
plt.show()
```
lo anterior lo aplicamos tambi칠n en Reverse 

```bash
%%bash
zcat /content/drive/MyDrive/Analisis_Posdoc/PR69/HA1AB3SS04_S4_L1_R2_001.fastq.gz | awk 'NR%4 == 2 {lengths[length($0)]++ ; counter++} END {for (l in lengths){print l, lengths[l]}; print "total reads: " counter}'
```

```bash
#Output de distribuci칩n de longitudes de secuencias y graficar en matplotib
%%bash
zcat /content/drive/MyDrive/Analisis_Posdoc/PR69/HA1AB3SS04_S4_L1_R2_001.fastq.gz | awk 'NR%4 == 2 {lengths[length($0)]++ ; counter++} END {for (l in lengths){print l, lengths[l]}}' | sort -n | uniq -c > /content/drive/MyDrive/Analisis_Posdoc/read_length2.txt
```

```python
read_file2 = pd.read_csv (r'/content/drive/MyDrive/Analisis_Posdoc/read_length2.txt',header=None)
read_file2.to_csv (r'/content/drive/MyDrive/Analisis_Posdoc/read_lengthR2.csv', index=None,header=None)
```

```python
read_file2[0] = read_file2[0].astype(str)
df2 = read_file2[0].apply(lambda x: x.strip(" "))
df2 = pd.DataFrame(df2.str.split(' ',2).tolist(),
                                 columns = ['fips','length', 'ocurrences'])
df2
df2=df2.astype(float)
```

```python
##Graficar la longitud de secuencia contra las ocurrencias
graficaR2 = df2.plot(x= 'ocurrences', y= 'length', kind ='line')
plt.show()
plt.savefig("ReadlenghtR2.jpg", bbox_inches='tight')
```
Lo siguiente puede ser opcional.

### c) bloques para mostrar solo secuencias o secuencias repetidas

```bash
#Desplegar solo la informaci칩n de la secuencia
%%bash
zcat /content/drive/MyDrive/Analisis_Posdoc/PR69/HA1AB3SS04_S4_L1_R1_001.fastq.gz | awk 'NR % 4 == 2 {print;}' | head -n 10
```

```bash
%%bash
zcat /content/drive/MyDrive/Analisis_Posdoc/PR69/HA1AB3SS04_S4_L1_R2_001.fastq.gz | awk 'NR % 4 == 2 {print;}' | head -n 10
```
podemos considerar un output txt para las secuencias repetidas

```bash
#Observar barcodes-secuencias que se presentan m치s frecuentemente
%%bash
zcat /content/drive/MyDrive/Analisis_Posdoc/PR69/HA1AB3SS04_S4_L1_R1_001.fastq.gz | awk 'NR % 4 == 2 {print;}' | sort | uniq -c | sort -n -r | head -n 10
zcat /content/drive/MyDrive/Analisis_Posdoc/PR69/HA1AB3SS04_S4_L1_R1_001.fastq.gz | awk 'NR % 4 == 2 {print;}' | sort | sort -n -r | uniq -c > /content/drive/MyDrive/Analisis_Posdoc/Sec_rep1.txt
```
```bash
%%bash
zcat /content/drive/MyDrive/Analisis_Posdoc/PR69/HA1AB3SS04_S4_L1_R2_001.fastq.gz | awk 'NR % 4 == 2 {print;}' | sort | uniq -c | sort -n -r | head -n 10
zcat /content/drive/MyDrive/Analisis_Posdoc/PR69/HA1AB3SS04_S4_L1_R2_001.fastq.gz | awk 'NR % 4 == 2 {print;}' | sort | sort -n -r | uniq -c > /content/drive/MyDrive/Analisis_Posdoc/Sec_rep2.txt
```

## 5. Pre procesamiento: analisis de calidad usando FASTQC y FASTP

El archivo FastQ que hab칤amos abordado [anteriormente](#4-comencemos-explorando-las-reads), 
consta de cuatro l칤neas:

&#x1F535; 1. Nombre de la secuencia (header - id del secuenciador, coordenadas del spot, flow-cell, adaptador, etc.)

&#x1F535; 2. Secuencia

&#x1F535; 3. Espaciador (+), que opcionalmente puede contener m치s texto, y

&#x1F535; 4. Valores de calidad: Q Score - alfanum칠rico. Correspondientes a los nucle칩tidos en l칤nea 2
    
Tal como se observa en la siguiente imagen:
![Estructura FastQ](https://user-images.githubusercontent.com/13104654/204933554-fef6cf9a-f8d4-4e52-ad1b-a831d5bfdd92.png)

Los scores de calidad (Q) representados en la cuarta l칤nea, que corresponden a caracteres ASCII, reflejan, en escala logar칤tmica, la probabilidad de que esta base en particular fuera llamada incorrectamente (P<sub>error</sub>).

```math
Q = -10 log_{10} P               
```
```math
P_{error} = 10^{-Q/10}
```
Lo cual corresponde generalmente a:

![Phred Quality score](https://user-images.githubusercontent.com/13104654/205389945-0d25371a-f02b-4db0-8e80-07e2cedf0e41.png)

Hay que considerar adem치s el m칠todo de codificado dependiendo de plataforma:

![Quality scores dependiendo de la plataforma de secuenciaci칩n](https://user-images.githubusercontent.com/13104654/205388609-2d6df438-0aea-4a9e-a612-37563d0e83e6.png)

As칤, podemos adem치s, aplicar otro c칩digo para determinarr si el score de nuestras lecturas corresponde a Phred+33, Phre+64 o Solexa+64

```bash
zcat /content/drive/MyDrive/Analisis_Posdoc/PR69/HA1AB3SS04_S4_L1_R1_001.fastq.gz | head -n 10000 |\
  awk '{if(NR%4==0) printf("%s",$0);}' |  od -A n -t u1 | \
  awk 'BEGIN{min=100;max=0;} \
      {for(i=1;i<=NF;i++) \
          {if($i>max) max=$i; \
               if($i<min) min=$i;}}END \
          {if(max<=74 && min<59) \
                     print "Phred+33"; \
           else \
           if(max>73 && min>=64) \
                     print "Phred+64"; \
           else \
           if(min>=59 && min<64 && max>73) \
                     print "Solexa+64"; else print "Unknown score encoding!";}' --- [Table of contents](/introduction/terminology_index.html)
```

Para entender un poco m치s acerca de [calidades](https://maq.sourceforge.net/qual.shtml) y los archivos fastq podemos ir a la documentaci칩n oficial de [FastQ](https://maq.sourceforge.net/fastq.shtml) y este [art칤culo](https://pubmed.ncbi.nlm.nih.gov/9521921/), adem치s de esta [nota t칠cnica](https://www.illumina.com/documents/products/technotes/technote_Q-Scores.pdf) de Illumina.


Tomando en cuenta lo anterior, podemos utilizar algunas herramientas para identificar problemas de calidad en las lecturas, con el fin no solo de mantener las secuencias adecuadas si no tambi칠n de reducir el tama침o del archivo, evitar contaminaci칩n, etc.

Entre las herramientas a utilzar tenemos:

# 5.1 Fastqc
Para correr FastQC en los archivos de secuencias dentro de google colab usamos el siguiente bloque de c칩digo:

```python
# Pre-alignment QA 
!fastqc /content/drive/MyDrive/Analisis_Posdoc/PR69/HA1AB3SS04_S4_L1_R1_001.fastq.gz
!fastqc /content/drive/MyDrive/Analisis_Posdoc/PR69/HA1AB3SS04_S4_L1_R2_001.fastq.gz
```
Los archivos de salida son html y abarcan las siguientes evaluaciones:

## 5.1.1. Estad칤stica simple

El primer apartado de estad칤stica simple contiene el nombre del archivo, el n칰mero total de secuencias, si existen secuencias de mala calidad, longitud de las secuencias y el contenido de GC. Ya se hab칤a abordado en los scripts anteriores la determinaci칩n del total y longitud de secuencias, por lo que nos sirve para corroborar. En este apartado no se generan warnings o fails.


![Panorama general y vista de los estad칤sticos iniciales](https://user-images.githubusercontent.com/13104654/205708653-93a21bca-be14-44e7-839a-fba67d08786e.png)

## 5.1.2.  Calidad de secuencias por base

Este es el valor de confianza de base con base en el Phred score que designa las series de score de calidad de las bases completas en su respectica locaci칩n en el archivo. un valor m치s all치 de Q30 es considerado bueno, mientras que uno arriba de Q20 es generalmente aceptado.
En este apartado se muestra una revisi칩n del rango de los valores de calidad a trav칠s de todas las bases en cada posici칩n en los archivos FASTQ. 
En cada posici칩n se muestra una boxplot con bigotes. En la gr치fica podemos definir una mediana (l칤nea roja central), rangos intercuartiles 25-75%(cajas amarillas), los bigotes representan los puntos del 10 y 90% y la calidad media (l칤nea azul). 

![calidad de secuencias por base para la lectura R1 de P69](https://user-images.githubusercontent.com/13104654/205745971-2a852136-b15d-431f-8720-de0edb5af83c.png)


El eje y corresponde a los *scores* de calidad, el cual es dividido con un fondo verde, naranja y rojo, siendo el fondo verde para los mejores *scores*, el naranja para los *scores* de no tan buena calidad y el rojo a los de calidad pobre (entre m치s alto el *score* mejor). 

Es normal para todas las plataformas que conforme avance la corrida la calidad disminuya. En esta parte se puede generar un warning, en el caso de que el cuartil de cualquier base sea menor de 10 o si la mediana es menor de 25 y fails si el cuartil es menor de 5 y la mediana menor de 20.

En el an치lisis que se realiz칩 del genoma de P69 se muestra que la calidad media no cae al fondo rojo y su comportamiento es t칤pico disminuyendo la calidad con la corrida. 
Se observa en la 칰ltima parte solo la mediana de una caja en el umbral de 20, y los cuartiles menores de 10 pero mayores de 5, por lo tanto solo se lanza un warning, el cual ser치 resuelto al realizar el preprocesamiento.  


## 5.1.3.  Calidad de secuencias por pozo (*flowcell*) 

![illumina_flowcell](https://user-images.githubusercontent.com/13104654/212420432-e0c77336-d557-4a28-a25e-6e03ef1ab5a8.png)

En este apartado se muestra un heatmap de las p칠rdidas de calidad posicional, es decir se grafica la calidad de las llamadas de bases contra la posici칩n f칤sica del secuenciador de la cual provienen. En los secuenciadores illumina, el 치rea del *flowcell* se divide artificialmente en franjas (superficie superior e inferior) y 
estas se subdividen en mosaicos (치reas arbitrarias que se analizan por separado en la canalizaci칩n de llamadas). Observar la calidad por mosaico identificar치 este tipo de errores. Se espera siempre la p칠rdida de calidad conforme los ciclos se incrementan, por ello resulta 칰til realizar una normalizaci칩n para representar la calidad. As칤 un buen gr치fico se observar치 en blanco (s칩lido azul rey brillante). 
De esta forma, los problemas se pueden manifestar de varias formas, en la prueba de P69:

![P69 calidad de secuencia por flowcell R1](https://user-images.githubusercontent.com/13104654/210288959-a6367307-2827-4ff1-b6ec-2dfb468564c0.png)

Puede haber una p칠rdida aleatoria de calidad en las posiciones y ciclos, lo cual indica un problema generalizado en el que m치s com칰nmente se sobrecarga la celda. En el an치lisis de calidad de la imagen de la cepa P69 se observa algo de este problema generalizado con la corrida aunque algo menos intenso. Resulta un tanto problem치tico si mosaicos aparecen en 치reas amplias y localizadas  del *flowcell*.

Si se pueden observar las p칠rdidas de calidad en mosaicos espec칤ficos entonces es posible removerlos del an치lisis *downstream*, lo que resultar칤a algo problem치tico de estar al inicio de la corrida. 

Ya que no sabemos cuantas lecturas son afectadas entonces la mitigaci칩n en este caso (P69) podr칤a resultar un problema (al remover lecturas se podr칤a perder informaci칩n).

## 5.1.4.  Scores de calidad por secuencia 
Este apartado muestra un gr치fico del n칰mero de secuencias (Y) contra la escala logar칤tmica del Phred (X), indicando la calidad de cada lectura:

![Calidad por secuencia](https://user-images.githubusercontent.com/13104654/210292722-b817acd1-1c04-415f-b470-91bc1f2aa7fd.png)

Phred score = 30 indica un rango de error de 1 base en 1000, o una exactitud de 99.9%.
Phred score = 40 indica un rango de error de 1 base en 10,000, o una exactitud de 99.99%.
Si el Phred score es < 27 se obtendr치 un warning y por debajo de 20 se dar치 un fail. 

En el caso de P69, el promedio de calidad es 36, lo cual es bueno.

## 5.1.5.  Contenido de bases por secuencia

En el caso del contenido de bases por secuencia, este apartado nos muestra, como el nombre lo indica, la composici칩n porcentual de las bases en cada posici칩n de la secuencia. Como habr칤a que esperar esta composici칩n debe permanecer estable en todos los ciclos, claro tomando en cuenta que el contenido de bases puede variar dependiendo de ciertos factores como la especie. En algunos casos podemos observar un sesgo en las primeras partes de la corrida, como es el caso del presente an치lisis P69. Se observa claramente que dicho sesgo se disipa en el resto de la corrida. 


![Composici칩n de secuencia](https://user-images.githubusercontent.com/13104654/210295270-29332fcd-2e65-4814-9439-5f7f743b6ab8.png)


En este apartado se puede generar una  :warning: **alerta**, si el contenido de bases var칤a m치s del 10% en cualquier posici칩n, y generar치 un :x: **fail** si este porcentaje de variaci칩n es mayor al 20%.

La causa de este sesgo puede ser el paso de *priming* aleatorio en la producci칩n de las librer칤as. A pesar de que los hexameros en el priming deben presentarse con igual frecuencia en el mix y deber칤an realizar el *prime* con eficiencia similar, en la realidad no se da el caso y ciertos hex치meros son favorecidos durante este paso.

쮼ntonces, el sesgo tendr칤a implicaciones en los an치lisis downstream?. Hay algunos puntos a tomar en cuenta:

- Es posible que como parte del sesgo haya un incremento en el *mis-priming* - ocasionando un n칰mero alto de *mis-called* bases al inicio de la secuencia, y, 
- Es posible que la selecci칩n del sesgo introducido tenga un efecto significativo en la capacidad de la librer칤a de medir el contenido original debido a ciertas secuencias favorecidas.

Sin embargo estos puntos pueden no representar un gran problema ya que son f치cilmente detectados,  algunos mencionan que pueden mitigarse por un *Trimming 5'*, sin embargo esto no es un arreglo. Ya que la composici칩n sesgada es creada por la selecci칩n de fragmentos de secuenciado y no por errores de llamadas de bases, el 칰nico efecto del *trimming* es cambiar de tener una libreria que inicia en posiciones sesgadas a una que inicia m치s all치 de dichas posiciones. 

La 칰nica forma de resolver este problema ser칤a introducir nuevos kits de preparaci칩n de librer칤as con una menor disposici칩n al sesgo en el paso del *priming*, sin embargo, a pesar de la advertencia,  no parece que haya consecuencias serias para los an치lisis posteriores, ir칩nicamente en RNA-seq son m치s sospechosas las librer칤as que no presentan este artefacto.

En este [art칤culo](https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0085583) se documenta el *mis-priming* en RNA-seq

Algunas de las razones m치s comunes de un warning o fail en este apartado son:
Secuencias sobrerepresentadas, sesgo en la fragmentaci칩n y composici칩n sesgada de las librer칤as (que a veces ocurre naturalmente).

En el presente caso tambi칠n se observa una desviaci칩n al final, si se est치 analizando una biblioteca que ha sido recortada agresivamente por el adaptador, naturalmente introducir치 un sesgo de composici칩n al final de las lecturas, ya que las secuencias que coinciden con tramos cortos del adaptador se eliminan, dejando solo las secuencias que no coinciden. Por lo tanto, es probable que las desviaciones repentinas en la composici칩n al final de las bibliotecas que han sufrido un recorte agresivo sean falsas.


## 5.1.6.  Contenido de GC por secuencia

Este apartado muestra en un plot, el contenido porcentual total de GC para todas las lecturas (n칰mero total de reads vs porcentaje de bases G y C por lectura), comparando contra una "distribuci칩n te칩rica" de GC's, asumiendo un contenido uniforme para todas las lecturas, el pico central corresponde al contenido de GC promedio del genoma subyacente. Dado que el contenido de GC del genoma no se conoce, el contenido modal de GC es calculado de datos observados y usado para construir la distribuci칩n de referencia.

![Contenido de GC](https://user-images.githubusercontent.com/13104654/210295287-8ed4d1b0-051f-498d-b5f9-d2cdbb5d60c3.png)

 Se observa un 丘멆잺**warning** si el 15% total de las secuencias caen fuera de la distribuci칩n normal.
 
 Se obtendr치 un :x:**fail** si m치s del 20% (el manual FastQC indica 30%) de las secuencias est치n fuera de la distribuci칩n normal.
 Los fails son generalmente debidos a contaminaci칩n, frecuentemente por secuencias de adaptadores.

Una distribuci칩n de forma inusual podr칤a indicar una librer칤a contaminada o alguna otra clase de subset sesgado. Una distribuci칩n normal cambiada 칤ndica alg칰n sesgo sistem치tico, el cual es independiente de la posici칩n de la base. Si existe un error sistem치tico, este no ser치 marcado como error por que no se sabe cual deber칤a ser el contenido de GC del genoma.

Existen otras situaciones en las cuales una distribuci칩n inusual se puede presentar. Por ejemplo, con RNA seq puede haber una distribuci칩n mayor o menor del contenido medio de GC entre los transcritos, causando que el gr치fico observado sea m치s amplio o m치s estrecho que una distribuci칩n normal ideal.

## 5.1.7.  Contenido de N por base 

Si un secuenciador no puede llamar una base con confianza suficiente entonces ser치 sustituido normalmente con un N m치s que una llamada de base convencional.

Este m칩dulo gr치fica el porcentaje de "llamadas" de base en cada posici칩n para las cuales una N fue considerada.

![Contenido de N P69](https://user-images.githubusercontent.com/13104654/210295307-9831c8c6-f696-4640-ad40-0efc91a27528.png)

Idealmente el contenido de N por base ser칤a una l칤nea plana en 0% sobre el eje Y, indicando que todas las bases han sido "llamadas".

  - Se recibe un :warning: **warning** si el contenido de N es igual o mayor de 5%,
  - Tendremos un :x: **fail** si el contenido de N es igual o mayor a 20%.

El an치lisis de R1 para P69 muestra el resultado ideal para este m칩dulo.

## 5.1.8.  Distribuci칩n de la longitud de secuencia

Este gr치fico muestra, tal como hicimos en [apartados anteriores](#b-revision-del-numero-y-longitud-de-secuencias), la distribuci칩n de los tama침os de fragmentos en el archivo analizado. En muchos casos esto solo produce un gr치fico simple mostrando solo un pico de un solo tama침o, pero para archivos FASTQ con longitud variable, mostrara las cantidades relativas de cada tama침o de fragmento de secuencia. En este caso nuestro archivo R1 P69 muestra longitudes variables m치s peque침as (30-269pb) que el pico de 299pb. 

![Longitud de secuencias R1 P69](https://user-images.githubusercontent.com/13104654/210295322-a0759d95-e0a6-42cc-b699-343741a5974e.png)


Algunos secuenciadores (y kits de secuenciaci칩n) generan fragmentos de longitudes ampliamente variables, otros pueden generar fragmentos de longitud uniforme.
Incluso en librer칤as con longitud uniforme, algunos *pipelines* cortar치n secuencias para remover llamadas de bases de baja calidad del final o las primeras n bases si coninciden las primeras n bases del adapatador arriba del 90% (por defecto), algunas veces con n=1. 
Para secuenciaci칩n con Illumina, cada lectura deber칤a ser del mismo tama침o (?). 

Este m칩dulo arrojar치 un :warning:**warning** si hay cualquier variaci칩n en la longitud de las secuencias, el cual puede ser ignorado si se sabe que es normal para el tipo de datos que se tiene. 

Un :x: **fail** en este m칩dulo significa que al menos una secuencia tiene longitud de 0. 
El an치lisis de R1 P69 obtiene un warning ya que hay una gran variabilidad en la longitud de las secuencias, lo cual puede cambiar al realizar el trimming.


## 5.1.9.  Niveles de duplicaci칩n de secuencias

En este m칩dulo se grafican los niveles de duplicaci칩n de secuencias (eje x) contra el porcentaje de secuencias que muestran ese nivel de duplicaci칩n (eje y), y 

Hay dos l칤neas en el gr치fico:
游댮 l칤nea roja: Distribuci칩n para las secuencia de-duplicadas con las proporciones del conjunto de-duplicado las cuales provienen de diferentes niveles de duplicaci칩n en los datos originales.

游댯 l칤nea azul: Distribuci칩n de los niveles de duplicaci칩n para en conjunto completo de secuencias. 

![niveles de duplicaci칩n de secuencias en R1 P69](https://user-images.githubusercontent.com/13104654/210295333-f2d9ca7d-0193-4483-b601-e077f178b6c3.png)

La gr치fica de los niveles de duplicaci칩n de secuencias muestran en el eje x, el n칰mero de veces que una secuencia est치 duplicada, y en el eje y el porcentaje de secuencias que muestran ese nivel de duplicaci칩n. Normalmente un genoma tendr치 un nivel de duplicaci칩n de secuencias de 1 a 3 para la mayor칤a de las secuencias, con s칩lo un pu침ado de lecturas teniendo un nivel m치s alto que este; la l칤nea deber칤a tener la forma inversa a una gr치fica log.

En el presente an치lisis de R1 P69 se no se observan picos a la derecha de la gr치fica y solo un bajo nivel de duplicaci칩n al inicio

Un alto porcentaje de duplicaci칩n de secuencias es un indicativo de contaminaci칩n.

Este m칩dulo nos arrojar치 un :warning: **warning** si m치s del 20% de las secuencias son duplicadas.

Tendr칠mos un :x: **fail** si m치s del 50% de las secuencias est치n duplicadas. 

Un warning o fail pueden ser resultado de artefactos de PCR.

#### M치s acerca de la duplicaci칩n:

>En una librer칤a diversa la mayor칤a de las secuencias se presentar치n solo una vez en el set final, un bajo nivel de duplicaci칩n puede indicar un muy alto nivel de coverage de la secuencia blanco, pero un alto nivel puede indicar una clase de sesgo por enriquecimiento ( por ejemplo en la amplificaci칩n por PCR).
Este m칩dulo cuenta el grado de duplicaci칩n para cada secuencia en el conjunto y crea un plot mostrando el numero relativo de secuencias con diferentes grados de duplicaci칩n.

>Con el fin de reducir los requerimientos de memoria para este m칩dulo, solamente las secuencias que se presentan en las primeras 200 000 en cada archivo son analizadas, pero esto deber칤a bastar para obtener una impresi칩n para los niveles de duplicaci칩n del archivo completo. 
Cada secuencia es rastreada al final del archivo para dar un conteo representativo del promedio del nivel de duplocaci칩n. 
Para reducir la cantidad de informaci칩n en el gr치fico final, cualquier secuencia con >10 duplicados son colocadas en esta categor칤a, por lo que no es inusual observar un leve incremento en esta categor칤a final. Si hay un gran incremento, significa que se tiene un alto n칰mero de secuencias con alto nivel de duplicaci칩n. 

>Debido a que la detecci칩n de la duplicaci칩n requiere de una coincidencia exacta de secuencias sobre la longitud completa de la secuencia, cualquier lectura por encima de 75pb de longitud son truncadas a 50pb para prop칩sitos del an치lisis, a칰n as칤, lecturas m치s largas son m치s propensas a contener errores de secuenciamiento por lo cual incrementar치 artificialmente la diversidad observada y tender치 a subrepresentar las secuencias altamente duplicadas.

>Para datos del *Whole Genome Shotgun* se espera que cerca del 100% de las lecturas sean 칰nicas (una sola vez en los datos de secuencia). La mayor칤a de las secuencias deber칤an caer hacia la izquierda del gr치fico para ambas l칤neas. Esto indica una librer칤a altamente diversa que no esta sobre secuenciada. Si la profundidad del secuenciamento es extremadamente alta (p. ej. >100x el tama침o del genoma) es inevitable que aparezcan duplicaciones de secuencias: en teor칤a solo hay un n칰mero finito de lecturas de secuencia completamente 칰nicas las cuales pueden ser obtenidas de cualquier muestra de DNA ingresada.

>Subconjuntos de enriquecimiento m치s espec칤ficos, o la presencia de contaminantes de baja complejidad tender치n a producir picos hacia la derecha del gr치fico. Estos picos de altos niveles de duplicaci칩n aparecer치n m치s frecuentemente en la l칤nea azul ya que conforman una mayor proporci칩n de la librer칤a original, pero usualmente desaparecen en el trazo rojo, ya que consiste de una porporci칩n no significante del conjunto deduplicado. Si los picos persisten en la l칤nea roja, entonces esto sugiere que hay un alto n칰mero de secuencias diferentes altamente duplicado lo que podr칤a indicar ya sea un conjunto de contaminantes o una duplicaci칩n t칠cnica severa.

>Es usualmente el caso para RNA seq donde existen algunos transcritos altamente abundantes y algunos con baja abundancia. Se espera que las lecturas duplicadas sean observadas para los transcritos de alta abundancia.


## 5.1.10. Secuencias sobre representadas

En el caso de este m칩dulo:
- Si se calcula que alguna secuencia representa m치s del 0.1 % del genoma completo ser치 etiquetada como una secuencia sobre-representada y se obtendr치 un :warning: **warning**
- La presencia de secuencias que representan m치s del 1% del genoma dar치 como resultado un :x: **fail**.

![Sobrerrepresentaci칩n R1 P69](https://user-images.githubusercontent.com/13104654/210641941-b7fb8d5a-2bce-4183-afa8-bf31b0cf0096.png)

En el presente an치lisis no se presentaron secuencias sobre-representadas.


> Una librer칤a normal contendr치 un conjunto diverso de secuencias, ninguna de las cuales individualmente hace una fracci칩n del completo. Encontrar que una sola secuencia se encuentra sobre representada en el conjunto o significa que es altamente significativa biol칩gicamente, que la librer칤a est치 contaminada o bien que no es tan diversa como se esperaba.

> FastQC enlista todas las secuencias que hacen m치s del 0.1% del total y por cada secuencia busca coincidencias en una base de datos de contaminantes comunes y reportar치 el mejor *Hit*. Los *Hits* deben ser de al menos 20pb en longitud y tener m치ximo un *mismatch*. Encontar uno no necesariamente significa que sea la fuente de contaminaci칩n pero puede apuntar en la direcci칩n correcta. Muchas secuencias de adapadores son muy similares entre s칤, por lo que podr칤a tenerse una coincidencia t칠cnicamente incorrecta.

> Los datos de RNAseq pueden tener algunos transcritos que son tan abundantes que se registran como secuencias sobre-representadas. 
Con los datos de DNA seq, ninguna secuencia deber칤a presentarse con suficientemente alta frecuencia para ser listada, pero algunas ocasiones podemos encontrar un peque침o porcentaje de lecturas de adaptadores.

> Podemos hacer BLAST de la secuencia sobre representada, si [Blastn](https://blast.ncbi.nlm.nih.gov/Blast.cgi?PROGRAM=blastn&PAGE_TYPE=BlastSearch&LINK_LOC=blasthome) no nos proporciona respuesta, podemos utilizar [VecScreen](https://www.ncbi.nlm.nih.gov/tools/vecscreen/).


## 5.1.11. Contenido de adaptadores 

Este m칩dulo busca secuencias espec칤ficas de adaptadores.

   - Una secuencia que representa m치s del 5% del total causar치 un :warning: **warning** en este m칩dulo.
   - Una secuencia que represente m치s del 10% del total causar치 un :x: **fail**.

![Contenido de adaptadores R1 P69](https://user-images.githubusercontent.com/13104654/210295352-5c134059-dc4a-4e72-bee1-18e3ee3eadbb.png)

Nuestro an치lisis no muestra contaminaci칩n con secuencias de adaptadores, lo cual es ideal. 
Si existiera un n칰mero significativo de secuencias de adaptadores, se debe utilizar un programa para recortarlos y realizar el an치lisis de calidad nuevamente.

Otros gr치ficos relacionados pueden consultarse en [Documentaci칩n Contenido de K-mer FastQC](https://www.bioinformatics.babraham.ac.uk/projects/fastqc/Help/3%20Analysis%20Modules/11%20Kmer%20Content.html) y m치s problem치ticas en [![QC Fail]](https://sequencing.qcfail.com/).


Lo anterior hay que correrlo para las lecturas R2. Luego podemos utilizar Multiqc para tomar ambos resultados de calidad o bien podemos usar fastp para realizarlo en un solo paso.

## 5.1.12 Multiqc

El siguiente bloque de c칩digo nos sirve para correr multiqc en colab.

```python
# Pre-alignment Multiqc summary file 
!multiqc .

import multiqc
#El an치lisis se hace sobre los archivos de fastqc para que te entregue un reporte conteniendo todo
multiqc.run('/content/drive/MyDrive/co패digos/Secuencias_UADY/50-3_S19_L001_R2_001_fastqc.zip')

```
Es una herramienta que busca todos los archivos de control de calidad de nuestras secuencias y las resume en un solo reporte, adem치s nos permite subrayar, por ejemplo,
ciertas muestras dentro del reporte, cambiar nombres o bien bajar las gr치ficas (interactivas) generadas a diferentes resoluciones. 
(es mejor, de momento, tratar de correr esta herramienta en entorno local (de preferencia en linux, unix o wsl) por que no he averiguado como correrla desde colab y que no la coloque en la ventana del cuaderno de trabajo si no que entregue el output externo).



# 5.2 Fastp
Fastp es una herramienta que realiza el preprocesamiento y filtrado de calidad de forma paralela y soporta lecturas Single end y Paired end.
M치s informaci칩n se puede encontrar en el [repositorio](https://github.com/OpenGene/fastp#simple-usage) de los desarrolladores.

A comparaci칩n de FASTQC, fastp ofrece resultados tanto para los datos de prefiltrado como para los datos de post-filtrado, permitiendo una evaluaci칩n del efecto del filtro comparando directamente las gr치ficas y reporta sus resultados tanto en formato HTML como en formato JSON, siendo este 칰ltimo manualmente optimizado para facilitar su lectura (m치s acerca de la descripci칩n en el [art칤culo](https://academic.oup.com/bioinformatics/article/34/17/i884/5093234)).
 
Para correr Fastp en los archivos de secuencias (con los datos para filtrado por defecto) dentro de google colab usamos el siguiente bloque de c칩digo:

```python
# Control de calidad y reporte 
!fastp -i /content/drive/MyDrive/Analisis_Posdoc/PR69/HA1AB3SS04_S4_L1_R1_001.fastq.gz -I /content/drive/MyDrive/Analisis_Posdoc/PR69/HA1AB3SS04_S4_L1_R2_001.fastq.gz -o content/drive/MyDrive/Analisis_Posdoc/PR69/salidas/HA1AB3SS04_S4_L1_R1_001.fastq.gz  -O /content/drive/MyDrive/Analisis_Posdoc/PR69/salidas/HA1AB3SS04_S4_L1_R2_001.fastq.gz

```
Si se requiere establecer un l칤mite de longitud para filtrado se utiliza -l, para establecer el nombre de los archivos de salida -j -h, m치s opciones [aqu칤](https://github.com/OpenGene/fastp#all-options)

```python
# Control de calidad y reporte 
!fastp -i /content/drive/MyDrive/Analisis_Posdoc/PR69/HA1AB3SS04_S4_L1_R1_001.fastq.gz -I /content/drive/MyDrive/Analisis_Posdoc/PR69/HA1AB3SS04_S4_L1_R2_001.fastq.gz -o content/drive/MyDrive/Analisis_Posdoc/PR69/salidas/HA1AB3SS04_S4_L1_R1_001.fastq.gz  -O /content/drive/MyDrive/Analisis_Posdoc/PR69/salidas/HA1AB3SS04_S4_L1_R2_001.fastq.gz -R content/drive/MyDrive/Analisis_Posdoc/PR69/salidas/fastp_report

#o tambi칠n de esta forma
# Control de calidad y reporte 
!fastp -i /content/drive/MyDrive/Analisis_Posdoc/PR69/HA1AB3SS04_S4_L1_R1_001.fastq.gz -I /content/drive/MyDrive/Analisis_Posdoc/PR69/HA1AB3SS04_S4_L1_R2_001.fastq.gz -o content/drive/MyDrive/Analisis_Posdoc/PR69/salidas/HA1AB3SS04_S4_L1_R1_001.fastq.gz  -O /content/drive/MyDrive/Analisis_Posdoc/PR69/salidas/HA1AB3SS04_S4_L1_R2_001.fastq.gz --json="HA1AB3SS04_S4_L1.json" --html="HA1AB3SS04_S4_L1.html" -l 150 --detect_adapter_for_pe -c --cut_right --cut_front -p --failed_out="failed_seqsPR69.fastq.gz"
```
> Cut_right equivale a SLIDING WINDOW en Trimmomatic mueve una ventana deslizante desde el frente al final, si encuentra una ventana con calidad media < *Threshold*, se deshace de las bases en la ventana y la parte derecha, luego para. 


## 5.2.1 Summary

En la salida primeramente podemos observar un resumen general antes y despu칠s del filtrado, as칤 como el resultado del filtro
aplicado, esto lo muestra para los dos archivos de lecturas:

![fastp_summary](https://user-images.githubusercontent.com/13104654/213575454-29eaae55-82c1-4637-b1a5-895cd369057a.png)

En el caso de PR69, con los filtros por defecto, podemos observar que las lecturas de baja calidad contaron para un 3.6% del total, 
sin un porcentaje significativo de N ni lecturas cortas.

## 5.2.2 Adaptadores o mal ligado 

La siguiente secci칩n muestra las ocurrencias de adaptadores de **ambos** archivos de lecturas.

![adapters_fastp](https://user-images.githubusercontent.com/13104654/213586493-70e52e97-87c2-465c-b510-8b91969bd51b.png)

Para PR69 muestra un bajo porcentaje de adaptadores (0.04% R1 y 0.4% R2). 

En este caso Fastp puede detectar adaptadores y cortarlos lo que nos ahorra tiempo, sin embargo esto se puede realizar con un script aparte utilizando [Trimmomatic](#53-trimmomatic) (o con [cutadapt](#541-cutadapt)) 
para el filtrado de calidad, en este caso, habr칤a que correr nuevamente los an치lisis de calidad con Fastqc para ver como quedaron las secuencias.

## 5.2.3 Estimaci칩n del tama침o de inserto

En este apartado se muestra la distribuci칩n del porcentaje de lecturas (eje y) contra el tama침o de las lecturas (eje x) en un gr치fico interactivo,
podemos modificar el tama침o de los ejes y hacer zoom.
Esta estimaci칩n toma en cuenta el overlap de las lecturas *Paired end*.

En el caso de PR69 se encuentran 56.33% de lecturas no sobrelapadas por lo que podr칤an ser de tama침o <30 o >572 o bien con gran cantidad de errores de secuenciaci칩n.

![Insert Size Distribution](https://user-images.githubusercontent.com/13104654/213606759-021f3824-8b43-470b-917c-17cecc3d64d9.png)

## 5.2.4 Antes del Filtrado
Las secciones siguientes muestran gr치ficos interactivos, antes del filtrado de calidad,  correspondiendo primero a la **calidad**, 
la gr치fica es equivalente a la mostrada por fastqc en la secci칩n 5.1.2 [Calidad de secuencias por base](#512-calidad-de-secuencias-por-base), 

![Calidad_R1](https://user-images.githubusercontent.com/13104654/213797876-82e8a084-a316-42d6-9d73-8d938506a170.png)


luego se muestra el gr치fico de los 칤ndices del contenido de bases contra la posici칩n, incluido el contenido de Ns

![Contenido de bases_R1](https://user-images.githubusercontent.com/13104654/213798468-0381814c-c3a1-4790-ab4d-3a4e5edf345e.png)

 y finalmente un heatmap con el conteo de K-meros, 
donde las 치reas m치s oscuras representan cuentas mayores. Lo anterior primero para R1 y despu칠s para R2.

![Conteo de Kmer](https://user-images.githubusercontent.com/13104654/213798539-eacad1b7-1c3e-4d40-88aa-85b0d4932ea2.png)

La idea de los *K meros* es simple, se crea una ventana de longitud *k* y se desliza tomando un caracter al tiempo. Si la longitud de una secuencia de DNA dada es N, entonces tendremos:

```math
Total K-mer = N - k + 1               
```
Usualmente se buscan tres tipos de frecuencias, la cuenta total (que tantas veces aparece un *k-mero* en una secuencia dada), la cuenta diferida (si ha aparecido o no sin importar cuantas veces) y la cuenta 칰nica (aquellas que solo han aparecido una vez). 
El conteo de *k-meros* es 칰til para el ensamble, clustering y alineamientos, as칤 como para la correcci칩n de errores en secuenciado, la estimaci칩n del tama침o del genoma y la identificaci칩n de repeticiones. Computacionalmente es un proceso exigente.

![k-mer](https://user-images.githubusercontent.com/13104654/213822121-8dacf7ca-1e63-4d6d-9094-e6a807141c37.png)


## 5.2.5 Despu칠s del Filtrado
Luego aparece una secci칩n con gr침aficos para despu칠s del filtrado (que puede ser por defecto o definido de acuerdo a lo que se observe en los datos).

El html se encuentra en la carpeta de Drive que se indic칩 en *colab*, y la salida de archivos ya filtrados tambi칠n se encontraran donde se indico, con este archivo fastq podemos continuar con los siguientes an치lisis *Downstream*. 

fastp tambi칠n cuenta con una *flag* para realizar el *merge* de las dos lecturas. Esto una vez que se cuenta con las secuencias ya filtradas.


# 5.3 Trimmomatic

Para el filtrado y corte de adaptadores con trimommatic, se puede usar el siguiente bloque de c칩digo 
```python
# Trimming 
!trimmomatic PE -phred33 R1.fastq R2.fastq R1\_paired.fq.gz R1\_unpaired.fq.gz R2\_paired.fq.gz R2\_unpaired.fq.gz ILLUMINACLIP:contams\_forward\_rev.fa:2:30:10 LEADING:3 TRAILING:3 SLIDINGWINDOW:4:15 MINLEN:36
```

o bien podemos se침alarle la secuencia de adaptadores. En el caso de PR69, las secuencias no tienen adaptador (o eso creemos) y tienen la misma longitud. 
En el presente caso no conozco la secuencia de adaptadores de la plataforma pero si se requiere, aqui podemos encontrar algunos adaptadores [https://github.com/ATGenomics/adapters](https://github.com/ATGenomics/adapters)

El siguiente bloque de c칩digo se aplica en una m치quina local y no en google colab como hemos utilizado hasta ahora, podr칤a funcionar si llamamos el shell y le indicamos alguna ruta espec칤fica para clonar las secuencias del repositorio. 

*Para secuencias Paired End:

```shell
cd $HOME/ git clone https://github.com/ATGenomics/adapters.git $HOME/bin/adapters

adapters="$HOME/bin/adapters/NexteraPE-PE.fa"
```

adapt치ndolo para colab podr칤a ser de la siguiente manera:

```shell
%%shell

###Para no poner toda la direcci칩n asignamos una variable, probar si esto funciona
#### Asignar nombres de archivos de lecturas
#fwd="/content/drive/MyDrive/Analisis_Posdoc/PR69/HA1AB3SS04_S4_L1_R1_001.fastq.gz"
#rev="/content/drive/MyDrive/Analisis_Posdoc/PR69/HA1AB3SS04_S4_L1_R2_001.fastq.gz"
#name="PR69"

#Primero creamos el directorio adaptadores
mkdir -p /content/drive/MyDrive/Analisis_Posdoc/PR69/adapters

#luego clonamos el repositorio dentro de esta carpeta
cd /content/drive/MyDrive/Analisis_Posdoc/PR69/adapters git clone https://github.com/ATGenomics/adapters.git $HOME/bin/adapters

#una vez clonado se define como una variable a la secuencia de adaptadores que corresponda la plataforma que estemos usando
adapters="/content/drive/MyDrive/Analisis_Posdoc/PR69/adapters/NexteraPE-PE.fa"
```

En una m치quina local se activa el entorno qc 
`source activate qc`

Sin embargo en google colab esto no parece ser necesario puesto que simplemente se llama el shell o bash con la correspondiente funci칩n


```shell
%%shell
trimmomatic PE -phred33 -threads 16 \ fwd \ rev  \ /content/drive/MyDrive/Analisis_Posdoc/PR69/HA1AB3SS04_S4_L1_R1_001.trim.fq.gz \ /content/drive/MyDrive/Analisis_Posdoc/PR69/HA1AB3SS04_S4_L1_R2_001.trim.fastq.gz /Analisis_Posdoc/PR69/HA1AB3SS04_S4.trim.fq.gz \ ILLUMINACLIP:${adapters}:2:30:10 SLIDINGWINDOW:4:20 MINLEN:90 CROP:150
```
Es muy importante se침alar que en este caso hay que tomar en cuenta el orden en el que se colocan los par치metros.

>ILLUMINACLIP:${adapters} eliminamos adaptadores con cierta frecuencia (2:30:10)

>SLIDINGWINDOW: 4:20 cuatro nucle칩tidos en promedio tienen una calidad menor a 20 se elimina la secuencia (incluyendo el par).

>MINLEN: m칤nimo de largo 90

>CROP: Cortar la lectura a una longitud de 150


Trimmomatic realiza un *trimming* de calidad adaptativo, cortado de cabeza y cola y remoci칩n de adaptadores. Se puede revisar la documentaci칩n y bajar el programa [aqu칤](http://www.usadellab.org/cms/index.php?page=trimmomatic).

Una de las ventajas del programa es que permite trabajar con secuencias *Paired end*, reteniendo solamente pares coincidentes.
Otra ventaja es que permite coincidencias parciales y *overlapping* para la b칰squeda de adaptadores.

Las opciones que podemos utilizar son las siguientes:

## 5.3.1 Eficiencia y formato

>Las siguientes se usan siempre antes de la invocaci칩n de los archivos de entrada y salida

- *threads*: este ajuste modifica el n칰mero de "hilos" de CPU que Trimmomatic deber칤a usar en las computaciones. Una computadora t칤picamente tiene cerca de 2 n칰cleos. los cuales deber칤an corresponder a una cantidad de 4 hilos disponibles. 
- *phred*:  [-phred33 	-phred64]:  Este ajuste le dice al programa que codifique el archivo

> A partir de aqu칤 son las opciones que van despu칠s de la invocaci칩n de *Inputs/Outputs* (estas opciones se presentan en may칰sculas) 

Opciones para cambiar la codificaci칩n (ver en [Apartado 5](#5-pre-procesamiento-analisis-de-calidad-usando-fastqc-y-fastp)):
Si se requiere leer la codificaci칩n de un tipo y sacar la codificaci칩n de uno diferente, 칠stas opciones son las que se necesitan utilizar.

- TOPHRED33: Convierte *scores* de calidad a Phred-33
- TOPHRED64: Convierte *scores* de calidad a Phred-64 

### 5.3.1.1 Cortado (*Cropping*)

Trimmomatic cuenta con varias opciones que pueden ser usadas simult치neamente o no:

-LEADING: Corta bases del inicio de una lectura, si est치 por debajo del umbral de calidad - adaptativa
-TRAILING: Corta bases del final de una lectura, si est치 por debajo del umbral de calidad - adaptativa
-CROP: Corta la lectura a una longitud espec칤fica
-HEADCROP: Corta el n칰mero espec칤ficado de bases del inicio de una lectura.

LEADING y TRAILING son cortado adaptativo, lo que significa que cortar치n el inicio/fin de las lecturas si fallan la calidad especificada. Lo anterior difiere de CROP y HEADCROP, los cuales podr칤an cortar a una longitud o n칰mero de bases espec칤ficas (respectivamente), en este caso, el programa realizara el corte para todas las lecturas.

-MINLEN: se deshar치 de todas las lecturas que caen bajo una longitud especificada.

### 5.3.1.2 *Trimming* de calidad adaptativo

-SLIDINGWINDOW: realiza un trimming en una ventana de deslizamiento, cortando una vez que la calidad promedio caiga de un umbral especificado.
Toma dos valores como `SLIDINGWINDOW:4:15` lo que significa "Escanear la lectura con una amplitud de ventana de 4 bases, cortando cuando la calidad promedio por base caiga debajo de 5"   
   
   
It takes two values like SLIDINGWINDOW:4:15 which means Scan the read with a 4-base wide sliding window, cutting when the average quality per base drops below 15

### 5.3.1.3 *Trimming* de adaptadores

Finalmente, trimmomatic tomar치 un archivo con las secuencias de los adaptadores y las cortar치. Siguiendo por ejemplo la llamada: `ILLUMINACLIP:<fastaWithAdaptersEtc>:<seed mismatches>:<palindrome clip treshold>:<simple clip treshold>` d칩nde:

-fastaWithAdaptersEtc: Especifica el *path* a un archivo fasta conteniendo todos los adaptadores, secuencias PCR etc. El nombre de las diferentes secuencias dentro de este archivo determina como ser치n usadas.
-seedMismatches: Especifica la cuenta m치xima de *mismatches*, lo cu치l podr칤a seguir permitiendo una coincidencia completa.
-palindromeClipTreshold: especifica que tan precisa es la coincidencia entre las dos lecturas 'ligadas por adaptador' que deben ser pal칤ndromo para las lecturas *PE*
-simpleClipTreshold: especifica que tan precisa debe ser la coincidencia entre cualquier adaptador, etc contra una lectura.

  ![trimmomatic_adapter](https://user-images.githubusercontent.com/13104654/211375856-b34becba-e0e4-450d-8d0b-06552b13b296.png)

Existen 4 posibles escenarios que Trimmomatic puede cubrir:
A. Una secuencia t칠cnica es completamente cubierta por la lectura y as칤, un alineamiento simple podr치 identificarla.
B. Solamente existe una coincidencia parcial entre la secuencia t칠cnica y la lectura y as칤, es necesariio un alineamiento corto.
C. y D. Ambos pares son probados a la vez, permitiendo que suceda lo siguiente: "es mucho m치s confiable que un alineamiento corto (B.) y permite que se detecte la lectura del adaptador incluso cuando solo se ha secuenciado una base de este."

El umbral de clip palindr칩mico escencialmente dice que tan preciso debe ser el alineamiento de adaptadores. Esto es la probabilidad log10 de obtener una coincidencia por una posibilidad aleatoria, y as칤, los valores alrededor de 30 son recomendados.

Referencias: https://jshleap.github.io/bioinformatics/writting-jNGS_tutorial/#encoding
[Bolger *et al.*, 2014](https://academic.oup.com/bioinformatics/article/30/15/2114/2390096)

# 5.4 Otras herramientas
## 5.4.1 Cutadapt

Cutadapt busca el adaptador en todas las lecturas y lo remueve cuando lo encuentra. A menos que se use la opci칩n de filtrado, todas las lecturas que est치n presentes en el archivo *input* estar치n presentes en el *output*, algunas de ellas ya con trimm, otras no. Incluso las lecturas que fueron coradas a una longitud de 0 son un output. Esto puede ser modificado en el comando (opciones).
Puede detectar m칰ltiples tipos de adaptadores. Adaptadores 5' preceden la secuencia de inter칠s mientras que los 3' la siguen. Las distinciones se hacen dependiendo de donde se presenta la secuencia en la lectura. Adem치s tambi칠n permite el procesamiento de lecturas *Paired End*.


![imagen](https://user-images.githubusercontent.com/13104654/212785938-7cfd92e4-acfd-4e47-86af-cc90123776c3.png)


Con lo anterior en mente, es una herramienta vers치til para remover *primers* o en general oligos de las regiones que flanquean el DNA. La gu칤a de uso se puede encontrar en su [p치gina](https://cutadapt.readthedocs.io/en/stable/guide.html).

con el siguiente bloque de c칩digo se puede utilizar

```bash

cutadapt -a ADAPTER_FWD -A ADAPTER_REV -o out.1.fastq -p out.2.fastq reads.1.fastq reads.2.fastq

```
Referencia: https://jshleap.github.io/bioinformatics/writting-jNGS_tutorial/#encoding

## 5.4.2 Seqkit


:alien: 游놓 :alien: :alien: :alien: :alien: :alien: :alien: :alien: :alien: :alien: :alien: :alien: :alien: :alien: :alien: :alien: :alien: :alien: :alien: :alien: :alien: :alien: :alien: :alien: :alien: :alien: :alien: :alien: :alien: :alien: :alien: :alien: :alien: :alien: :alien: :alien: :alien: :alien: :alien: :alien:

# 5.5 N칰mero y longitud de secuencias despu칠s del filtrado de calidad

Una vez realizado el filtrado se pueden correr de nuevo los an치lisis de calidad (usando fastqc/multiqc o fastp). Adem치s podemos utilizar nuevamente los comandos de bash para analizar longitudes de lecturas, etc.

El bloque de c칩digo para estas revisiones (realizando el trimming con trimmomatic) ser칤a el siguiente:

> (Tambi칠n revisamos que se encuentren pareados, esta parte se puede omitir)

El siguiente bloque permite revisar si los archivos est치n pareados
```bash
##Para explorar que los archivos est치n pareados
%%bash
zcat /content/drive/MyDrive/Analisis_Posdoc/PR69/HA1AB3SS04_S4_L1_R1_001_Trim.fastq.gz | wc -l
zcat /content/drive/MyDrive/Analisis_Posdoc/PR69/HA1AB3SS04_S4_L1_R2_001_Trim.fastq.gz | wc -l
```
si queremos saber cual es el n칰mero de secuencias usamos el siguiente bloque de c칩digo, de nuevo usamos zgrep por que es un archivo comprimido y ahora usaremos los archivos de salida del trimming.

```bash
##revisar nuevamente la cantidad de secuencias
%%bash
zgrep '^@M02521' /content/drive/MyDrive/Analisis_Posdoc/PR69/HA1AB3SS04_S4_L1_R1_001_Trim.fastq.gz | wc -l
zgrep '^@M02521' /content/drive/MyDrive/Analisis_Posdoc/PR69/HA1AB3SS04_S4_L1_R2_001_Trim.fastq.gz | wc -l
```

Exploramos la longitud de secuencias. Para ello podemos usar awk de nuevo.

Para cada l칤nea de secuencia podemos contar cada caracter usando el par치metro NR (n칰mero de registros) y usando el contador y a침adiendo para imprimir en txt.

```bash
%%bash
zcat /content/drive/MyDrive/Analisis_Posdoc/PR69/HA1AB3SS04_S4_L1_R1_001_Trim.fastq.gz | awk 'NR%4 == 2 {lengths[length($0)]++ ; counter++} END {for (l in lengths){print l, lengths[l]}}' | sort -n | uniq -c > /content/drive/MyDrive/Analisis_Posdoc/read_length1Trim.txt

zcat /content/drive/MyDrive/Analisis_Posdoc/PR69/HA1AB3SS04_S4_L1_R2_001_Trim.fastq.gz | awk 'NR%4 == 2 {lengths[length($0)]++ ; counter++} END {for (l in lengths){print l, lengths[l]}}' | sort -n | uniq -c > /content/drive/MyDrive/Analisis_Posdoc/read_length2Trim.txt


```

el txt generado lo podemos importar y transformar nuevamente a csv para despu칠s graficarlo en matplotlib, se aplican los siguientes bloques:

```python
read_file = pd.read_csv (r'/content/drive/MyDrive/Analisis_Posdoc/read_length1Trim.txt',header=None)
read_file.to_csv (r'/content/drive/MyDrive/Analisis_Posdoc/read_lengthR1Trim.csv', index=None,header=None)

read_file = pd.read_csv (r'/content/drive/MyDrive/Analisis_Posdoc/read_length2Trim.txt',header=None)
read_file.to_csv (r'/content/drive/MyDrive/Analisis_Posdoc/read_lengthR2Trim.csv', index=None,header=None)

```

# 5.6 PhiX 

> Es posible usar esta librer칤a y aplicar este c칩digo, sin embargo, en este caso no se hizo una corrida por lo que este c칩digo queda en stand by y se podr칤a usar para futuras secuenciaciones (no me queda muy claro si solo podemos usar la secuencia para ver si hay contaminaci칩n por fagos en la librer칤a)

Para control de calidad interno 
[Phix](https://support.illumina.com/bulletins/2017/02/what-is-the-phix-control-v3-library-and-what-is-its-function-in-.html) o la librer칤a de control v3 PhiX (FC-110-3001) es derivada del genoma del bacteri칩fago, bien caracterizado, PhiX. Es una librer칤a concentrada de Illumina (10 nM en 10 췃l) que tiene un tama침o promedio de 500 pb y cuenta con una composici칩n balanceada de bases a ~45% GC y ~55% AT.

Puede servir como un control de calibraci칩n y puede ser secuenciado solo,  para usarlo en: C치lculos de phasing y prephasing, generaci칩n de matrices Cross talk (ref cruzada) y examinar el desempe침o promedio de las plataformas de secuenciaci칩n Illumina. 

Se puede bajar un programa [BWA](https://github.com/lh3/bwa#type), para realizar el index de la referencia.
BWA: es un paquete de software para el mapeo de secuencias de ADN contra un gran genoma de referencia, como el genoma humano. A mayor n칰mero de lecturas de Phix, mayor probabilidad de tener un Profago en el genoma problema. Evidentemente me quedar칤a con las secuencias que no mapearon vs PhiX.

El siguiente bloque de c칩digo es SOLAMENTE para aplicarse en el entorno local de una m치quina (no en colab)

```bash
#qc corresponde en este caso a la carpeta de trabajo donde se encuentran todas las secuencias en el presente bloque de c칩digo, depender치 de cada  persona y m치quina donde se trabaje (es el nombre que cada quien decide)

cd $HOME/Ensamble #Este comando va a corresponder con la carpeta en la que nos encontremos trabajando localmente, en el caso de colab esto no se realiza 
source activate qc #En este comando estamos activando la carpeta qc como la fuente para trabajar
tar -zxvf PhiX_Illumina_RTA.tar.gz && rm PhiX_Illumina_RTA.tar.gz # Este archivo se encuentra dentro de la carpeta qc, nosotros no contamos con este 
bwa index PhiX/Illumina/RTA/Sequence/Chromosomes/phix.fa -p 췂01_qc/phix췂 # Este es el comando que corresponde al programa BWA para hacer el index
conda deactivate
```
El siguiente bloque se utiliza para Mapear (por Alineamiento) las *lecturas* versus la referencia, en este caso PhiX:
Consta de tres pasos

1. script usando | Indexar y alinear vs esa referencia
2. Selecciona las secuencias que no mapean vs PhiX
3. Sort=ordenar esas secuencias no mapeadas


```bash 
#De igual forma primero nos movemos a la carpeta ensamble y activamos el entorno del archivo qc
cd $HOME/Ensamble 
source activate qc

#busca el alineamiento, selecciona las secuencias que no mapean y se ordenan dichas secuencias 

bwa mem -t 8 01_qc/phix \
    01_qc/R1.trim.fastq.gz \
    01_qc/R2.trim.fastq.gz | \
    samtools view -bS -f4 - | \
    samtools sort -@ 4 - -o 01_qc/PB69.phix.sorted.bam

samtools fastq \
    -1 01_qc/R1.trim.clean.fastq.gz \
    -2 01_qc/R2.trim.clean.fastq.gz \
    -s 01_qc/S.trim.clean.fastq.gz \
    01_qc/PB69.phix.sorted.bam
```

Se puede realizar el Conteo de las secuencias, NUEVAMENTE.
.clean son archivos de salida despu칠s de mapear vs PHIX (nosotros establecemos el nombre)

```bash
zcat R1.trim.clean.fastq.gz | awk 'END{ print NR/4 }'
zcat R2.trim.clean.fastq.gz | awk 'END{ print NR/4 }'
```
Si no se encuentran secuencias de Phix entonces se puede realizar el ensamble con las secuencias ya trimmeadas

https://github.com/Microfred/IntroBioinfo/blob/main/Unidad_3/Readme.md

  
## 6. Ensamble *De Novo*

Una vez se ha evaluado el control de calidad de las secuencias, 칠stas se encuentran mezcladas y, como si de un rompecabezas se tratara, hay que armarlo en el orden correcto. El m칠todo de alineamiento utilizado para realizar esta tarea se denomina ensamble. Una parte esencial del ensamble es el alineamiento, que involucra disponer de una cantidad masiva de lecturas de DNA, buscando regiones que coincidan unas con otras (regiones de alineamiento) y eventualmente unir el rompecabezas.

Para el Ensamble *De novo*, dependiendo de la plataforma de secuenciaci칩n es posible aplicar diferentes estrategias de ensamble:

![4 estrategias de ensamble](https://user-images.githubusercontent.com/13104654/212998923-3620318d-7258-49da-838f-3e63274b195f.png)
[Estrategias de ensamble *De Novo* en secuencias de lectura corta](https://academic.oup.com/bib/article/11/5/457/1746253?login=true)



Los algoritmos de ensamble son la colecci칩n de procesos para construir, a partir de cantidades de lecturas de secuencias cortas,  secuencias de DNA original. Las secuencias son alineadas unas con otras y las partes que se superponen son combinadas en una secuencia estrecha. Actualmente, existen dos m칠todos de algoritmos de ensamble, que diferiran de acuerdo a la complejidad de los datos de secuenciaci칩n. 


4.2.1 The overlap-layout-consensus/string graph assemblers
This algorithm recognizes intersects among combinations of reads to construct a graph of the connections between the
sequencing reads (Li et al., 2012). The overlap-layout-consensus (OLC) is computational intensive approach where the
complexity of computation increases with the total sequencing data used during assembling. Due to which this algorithm
of assembly becomes inexcusable with the sequencers like Illumina where millions of short sequence reads will be needed
for an assembly. After generating the graph, it visits through the each node using path called as Hamiltonian path, to construct
the final assembly. The layout stage of the algorithm reduces the complexity of the preliminary graph by condensing
the areas that unambiguously arose from the same genomic loci to the node where the line diverges with several potential
paths. It is far from straight forward to decide such a path. This gives subgraphs to make contigs that can be described as
unambiguously assembled unitig sequences that have high sequencing depth and linked to large numbers of other contigs.
Now, the unitig is then paired with other unitigs to form a scaffolds sequence (Bresler, Sheehan, Chan, & Song, 2012).
The last step of making the consensus process includes reading through the contiguous subgraphs and extracting the
sequence of consensus for reads from each subgraph. Another string graph algorithm involves same overlap graph theory
but slightly differs as it simplifies the graph by removing transitive edges that have redundant details (Chang et al., 2012).



Para el Ensamble *De novo* es posible aplicar diferentes estrategias 

![4 estrategias de ensamble](https://user-images.githubusercontent.com/13104654/212998923-3620318d-7258-49da-838f-3e63274b195f.png)
[Estrategias de ensamble *De Novo* en secuencias de lectura corta](https://academic.oup.com/bib/article/11/5/457/1746253?login=true)

kmergenie (contar k meros, para modificar ciertos par치metros para el ensamble)
Puede usarse Megahit, velvet, spades
 
[Megahit](https://github.com/voutcn/megahit#basic-usage)
[Li *et al.*, 2015](https://pubmed.ncbi.nlm.nih.gov/25609793/)
 
 B치sicamente, para el ensamble se usa el siguiente bloque de c칩digo para lecturas *Paired end* 
 
 ```Phyton
# !megahit -1 pe_1.fq -2 pe_2.fq -o out #Revisar como se realizar치 el output en colab
!megahit -1 /content/drive/MyDrive/Analisis_Posdoc/PR69/salidas/HA1AB3SS04_S4_L1_R1_001.fastq.gz -2 /content/drive/MyDrive/Analisis_Posdoc/PR69/salidas/HA1AB3SS04_S4_L1_R2_001.fastq.gz -o /content/drive/MyDrive/Analisis_Posdoc/PR69/salidas/ensamble/HA1AB3SS041.megahit_asm
 ```
 
 Los contigs pueden encontrarse en el directorio de salida (para colab tenemos que establecerlo) como `final.contigs.fa`

para observar la gr치fica de contigs

https://github.com/voutcn/megahit/wiki/An-example-of-real-assembly


```Phyton
!megahit_toolkit contig2fastg 99 k99.contigs.fa > k99.fastg
 ```
 
Algunos tips acerca del ensamble lo podemos encontrar [aqu칤](https://github.com/voutcn/megahit/wiki/Assembly-Tips)


 
 
 pipeline: TORMES https://github.com/nmquijada/tormes








Ejemplo Metodolog칤a art칤culo
ExperimentalDesign,MaterialsandMethods
B.australimarisB28Awaspreviouslyisolatedandidentifiedwith16SrRNAwithGenBankac-cessionnumberMT010836.GenomicDNAwasextractedusingtheMonarch춽 GenomicDNAPu-rificationKit(NewEnglandBiolabs.).IlluminaHiSeq4000paired-end(2칑151bp)sequencingofB.australimarisB28AwasperformedbyMacrogenInc.(Seoul,Korea).ThelibrarywasprocessedusingtheNexteraXTDNALibraryPreparationKit(96samples)(Illumina,Inc.,SanDiego,CA,USA).Totalsequencingreads5,130,218of4,447,316weremapped.Aftermapping,Sambamba[10]andSAMTools[11]wererespectivelyusedtoremoveduplicatedreadsandidentifyvari-ants.Thereadswereassembledinto58contigs,aGCcontentof41.60%usingGCEAssembler(version1.2;https://cge.cbs.dtu.dk/services/Assembler/)[12].TheassembleddatawasannotatedusingRASTrapidannotationusingsubsystemtechnologyversion2.0[68].BacterialsecondarymetabolitebiosynthesisgeneclusterswereidentifiedandannotatedbyantiSMASHversion5.0and6.0usingassembledfastafileoutput[







